{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from string import digits\n",
    "#把每一个词找到相应的positive and neg score用一个interger表示 最终生成一个dictionary{word：(posint, negint),word2:(posint, negint).....}。\n",
    "# def getWordSenti(file_path='./resource/SentiWordNet_3.0.0_20130122.txt'):\n",
    "#     length = len(open(file_path,'r').readlines())\n",
    "#     f = open(file_path,'r', encoding='UTF-8')\n",
    "#     for i in range(27):\n",
    "#         f.readline()\n",
    "        \n",
    "#     sentiWord={}\n",
    "#     for i in range(27,length-1):\n",
    "#         textList=f.readline().split('\\t')\n",
    "#         posScore=float(textList[2].strip())\n",
    "#         negScore=float(textList[3].strip())\n",
    "#         posLvl = int(posScore/0.05)\n",
    "#         negLvl = int(negScore/0.05)\n",
    "        \n",
    "#         word = str(textList[4].strip())\n",
    "#         res = word.translate(str.maketrans('', '', digits))\n",
    "#         pureWord = res.strip(\"#\")\n",
    "#         arr = [posScore, negScore]\n",
    "#         sentiWord[pureWord] = arr\n",
    "     \n",
    "#     print(sentiWord)\n",
    "#     print(\"a\")\n",
    "\n",
    "#     return sentiWord\n",
    "        \n",
    "                  \n",
    "# def getSentiWordNet(file_path='./resource/SentiWordNet_3.0.0_20130122.txt'):\n",
    "#     length = len(open(file_path,'r').readlines())\n",
    "#     f = open(file_path,'r', encoding='UTF-8')\n",
    "#     for i in range(27):\n",
    "#         f.readline()\n",
    "\n",
    "#     idxsDict={}# record the id of the score\n",
    "#     for i in range(27,length-1):\n",
    "#         textList=f.readline().split('\\t')\n",
    "#         posScore=float(textList[2].strip())\n",
    "#         negScore=float(textList[3].strip())\n",
    "#         synsetTerms=textList[4].split(' ')\n",
    "#         for text in synsetTerms:\n",
    "#             temp=text.strip()\n",
    "#             l=len(temp)\n",
    "#             key=temp[:l-2]\n",
    "#             if int(posScore)==1:\n",
    "#                 posScore=0.99\n",
    "#             if int(negScore)==1:\n",
    "#                 negScore=0.99\n",
    "#             if key in idxsDict.keys():\n",
    "#                 idxsDict[key].add(int(posScore*10))\n",
    "#                 idxsDict[key].add(int(negScore*10)+10)\n",
    "# #                 arr = [int(posScore*10), int(negScore*10)+10]\n",
    "# #                 idxsDict[key] = arr\n",
    "#             if key not in idxsDict.keys():\n",
    "#                 idxsDict[key]=set([int(posScore*10)])\n",
    "#                 idxsDict[key].add(int(negScore*10)+10) \n",
    "    \n",
    "#     print(idxsDict)\n",
    "#     with open(\"a.txt\",'r') as f:\n",
    "#         for temp in idxsDict.keys():\n",
    "#             f.write(temp+' '+str(idxsDict[temp])+'\\n') \n",
    "            \n",
    "#     return idxsDict\n",
    "\n",
    "def deal(filename):\n",
    "    d = {}\n",
    "    for line in open(filename).readlines()[27:-1]:\n",
    "        line = line.strip()\n",
    "        sp = line.split('\\t')\n",
    "        words = sp[4].split()\n",
    "        for word in words:\n",
    "            word = word.split('#')[0]\n",
    "            if word in d.keys():\n",
    "                list1 = d[word]\n",
    "                if int(float(sp[2]) / 0.005) > int(float(list1[0])):\n",
    "                    list1[0] = int(float(sp[2]) / 0.005)\n",
    "                if int(float(sp[3]) / 0.005) > int(float(list1[1])):\n",
    "                    list1[1] = int(float(sp[3]) / 0.005)\n",
    "            else:\n",
    "                d[word] = [int(float(sp[2]) / 0.005), int(float(sp[3]) / 0.005)]\n",
    "                \n",
    "                \n",
    "    return d\n",
    "\n",
    "# def getsentiword_matrix(vocab_train_path='./pickle_data/vocab_train.pickle'):\n",
    "#     vocab_train=pickle.load(open(vocab_train_path,'rb'))\n",
    "#     sentiword_matrix=np.zeros((len(vocab_train),20),dtype=np.int32)\n",
    "#     idxsDict=getSentiWordNet()\n",
    "#     print(idxsDict)\n",
    "#     for i,word in enumerate(vocab_train.keys()):\n",
    "#         if word in idxsDict.keys():\n",
    "#             idxs=idxsDict.get(word)\n",
    "#             for j in idxs:\n",
    "#                 sentiword_matrix[i,j]=1               \n",
    "#     return sentiword_matrix, idxsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    filename = './resource/SentiWordNet_3.0.0_20130122.txt'\n",
    "    d = deal(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__=='__main__':\n",
    "# #     sentiword_matrix, dic_sentiwords = getsentiword_matrix()\n",
    "# #     print('sentiword_matrix shape',sentiword_matrix.shape)\n",
    "    \n",
    "# #     file = open('pickle_data/sentiword_matrix.pickle','wb')\n",
    "# #     pickle.dump(sentiword_matrix,file)\n",
    "# #     file.close()\n",
    "    \n",
    "# #     file = open('pickle_data/dic_sentiwords.pickle','wb')\n",
    "# #     pickle.dump(dic_sentiwords,file)\n",
    "# #     file.close()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 175]\n"
     ]
    }
   ],
   "source": [
    "print(d[\"terrible\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
