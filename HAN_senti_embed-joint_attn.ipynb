{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the train_copus_padded data from .pickle file\n",
    "file = open('pickle_data/train_copus_pad.pickle','rb')\n",
    "train_copus_padded = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/test_copus_pad.pickle','rb')\n",
    "test_copus_padded = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/vocab_train.pickle','rb')\n",
    "vocab_to_int_train = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/embedding_matrix','rb')\n",
    "embedding_matrix = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/train_label.pickle','rb')\n",
    "train_label = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/test_label.pickle','rb')\n",
    "test_label = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('pickle_data/sentiword_matrix.pickle','rb')\n",
    "sentiword_matrix = pickle.load(file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admusr/anaconda2/envs/python3_pengfei/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0,1,2'   #指定第一块GPU可用\n",
    "gpu_num = 3\n",
    "from keras.utils import multi_gpu_model\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.8  # 程序最多只能占用指定gpu50%的显存\n",
    "# config.gpu_options.allow_growth = True      #程序按需申请内存\n",
    "# sess = tf.Session(config = config)\n",
    "\n",
    "# !pip install paramiko\n",
    "import pickle\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Lambda, Masking\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Convolution1D, MaxPooling1D, GlobalMaxPooling1D, Input, Dense, Reshape, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import initializers\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "#from util.util_functions import getWordIdx\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test data shape: (25000, 30, 235) (25000, 30, 235)\n",
      "embedding_matrix shape: (106180, 300)\n",
      "snetiword_matrix shape: (106180, 20)\n",
      "vocabulary size: 106180\n",
      "max sent number in a review: 30 \n",
      "max words in a sentence: 235\n"
     ]
    }
   ],
   "source": [
    "print('train test data shape:',train_copus_padded.shape, test_copus_padded.shape)\n",
    "print('embedding_matrix shape:', embedding_matrix.shape)\n",
    "print('snetiword_matrix shape:', sentiword_matrix.shape)\n",
    "#the size of vocabulary\n",
    "vocab_size = len(vocab_to_int_train)\n",
    "print('vocabulary size:', vocab_size)\n",
    "# the maximal length of every sentence\n",
    "MAX_SENTS = train_copus_padded.shape[1]\n",
    "MAX_SENT_LENGTH = train_copus_padded.shape[2]\n",
    "print('max sent number in a review:', MAX_SENTS, '\\nmax words in a sentence:', MAX_SENT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention layer\n",
    "\n",
    "class AttLayer_joint(Layer):\n",
    "    def __init__(self, attention_dim, **kwargs):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttLayer_joint, self).__init__( **kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #assert len(input_shape) == 3\n",
    "        assert isinstance(input_shape, list)\n",
    "        self.W = K.variable(self.init((input_shape[0][-1], self.attention_dim)))\n",
    "        self.W2 = K.variable(self.init((input_shape[1][-1], self.attention_dim)))\n",
    "        self.b = K.variable(self.init((self.attention_dim, )))\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)))\n",
    "        self.trainable_weights = [self.W, self.W2,self.b, self.u]\n",
    "        super(AttLayer_joint, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=[None,None]):\n",
    "        # current mask shape: [batch_size, set_len]\n",
    "        mask = None\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=[None,None]):\n",
    "        # size of x :[batch_size, sel_len, attention_dim]\n",
    "        # size of u :[batch_size, attention_dim]\n",
    "        # uit = tanh(xW+b)\n",
    "        p = K.dot(x[0], self.W)+K.dot(x[1], self.W2)\n",
    "        uit = K.tanh(K.bias_add(p, self.b))\n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "\n",
    "        ait = K.exp(ait)\n",
    "\n",
    "        if mask[0] is not None:\n",
    "#             Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            ait *= K.cast(mask[0], K.floatx())\n",
    "            \n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        \n",
    "        weighted_input = x[0] * ait\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        return (input_shape[0][0], input_shape[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttLayer(Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        self.init = initializers.get('normal')\n",
    "        self.supports_masking = True\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)))\n",
    "        self.b = K.variable(self.init((self.attention_dim, )))\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)))\n",
    "        self.trainable_weights = [self.W, self.b, self.u]\n",
    "        super(AttLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        # current shape: [batch_size, set_len]\n",
    "        mask = None\n",
    "        return mask\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # size of x :[batch_size, sel_len, attention_dim]\n",
    "        # size of u :[batch_size, attention_dim]\n",
    "        # uit = tanh(xW+b)\n",
    "        uit = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "\n",
    "        ait = K.exp(ait)\n",
    "\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = x * ait\n",
    "        output = K.sum(weighted_input, axis=1)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):       \n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "gru_dim = 100\n",
    "dropout_rate = 0.3\n",
    "atten_dim = 100\n",
    "dense_dim = 50\n",
    "\n",
    "batch_size = 100\n",
    "epoch_num = 15\n",
    "\n",
    "categorical_label = True\n",
    "\n",
    "if categorical_label:\n",
    "    train_label_cat = np_utils.to_categorical(train_label)\n",
    "#     test_label_cat = np_utils.to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some Keras layers\n",
    "embedding_layer1 = Embedding(vocab_size, embedding_matrix.shape[1], input_length=MAX_SENT_LENGTH, \n",
    "                            weights=[embedding_matrix], trainable=False)\n",
    "embedding_layer2 = Embedding(vocab_size,sentiword_matrix.shape[1],input_length=MAX_SENT_LENGTH,\n",
    "                             weights=[sentiword_matrix], trainable=False)\n",
    "#sentiword_matrix.shape[1]\n",
    "\n",
    "rnn_layer1 = Bidirectional(GRU(gru_dim, dropout=dropout_rate, recurrent_dropout=dropout_rate, return_sequences=True, activation='relu'))\n",
    "rnn_layer2 = Bidirectional(GRU(50, dropout=dropout_rate, recurrent_dropout=dropout_rate, return_sequences=True, activation='relu'))\n",
    "rnn_layer3 = Bidirectional(GRU(gru_dim, dropout=dropout_rate, recurrent_dropout=dropout_rate, return_sequences=True, activation='relu'))\n",
    "#rnn_layer4 = Bidirectional(GRU(gru_dim, dropout=dropout_rate, recurrent_dropout=dropout_rate, return_sequences=True))\n",
    "# rnn_layer = GRU(gru_dim, dropout=dropout_rate, recurrent_dropout=dropout_rate, return_sequences=True)\n",
    "\n",
    "\n",
    "# cnn_layer = Convolution1D(nb_filter=50,filter_length=3,border_mode='same',activation='tanh',subsample_length=1)\n",
    "# max_pooling_layer = GlobalMaxPooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 235)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 235, 300)     31854000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, 235, 300)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 235, 20)      2123600     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 235, 200)     240600      masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 235, 100)     21300       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "att_layer_joint_1 (AttLayer_joi (None, 200)          30200       bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 34,269,700\n",
      "Trainable params: 292,100\n",
      "Non-trainable params: 33,977,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build sentence encoder model\n",
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "\n",
    "sent_embedding = embedding_layer1(sentence_input)  #input shape:(MAX_SENT_LENGTH),output shape:(MAX_SENT_LENGTH,embed dimension)\n",
    "sentiword_embedding = embedding_layer2(sentence_input)\n",
    "\n",
    "# mask out padding tokens\n",
    "sent_embedding = Masking(mask_value=0., input_shape=(MAX_SENT_LENGTH, embedding_matrix.shape[1]))(sent_embedding)\n",
    "\n",
    "sent_rnn = rnn_layer1(sent_embedding)#sent_lstm\n",
    "sentiword_rnn=rnn_layer2(sentiword_embedding)\n",
    "\n",
    "sent_att = AttLayer_joint(atten_dim)([sent_rnn,sentiword_rnn])#atten_dim\n",
    "#sentiword_att = AttLayer(atten_dim)(sentiword_rnn)\n",
    "#sent_output = keras.layers.concatenate([sent_att,sentiword_att])\n",
    "sentEncoder = Model(sentence_input,sent_att)\n",
    "#sentiwordEncoder = Model(sentence_input,sentiword_att)\n",
    "\n",
    "sentEncoder.summary()\n",
    "#sentiwordEncoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 30, 235)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 200)           34269700  \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, 30, 200)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 30, 200)           180600    \n",
      "_________________________________________________________________\n",
      "att_layer_1 (AttLayer)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 34,480,652\n",
      "Trainable params: 503,052\n",
      "Non-trainable params: 33,977,600\n",
      "_________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 30, 235)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 30, 235)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 30, 235)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 30, 235)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 2)            34480652    lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Concatenate)           (None, 2)            0           model_2[1][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "                                                                 model_2[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 34,480,652\n",
      "Trainable params: 503,052\n",
      "Non-trainable params: 33,977,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build document encoder model\n",
    "review_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "review_encoder = TimeDistributed(sentEncoder)(review_input)   # out shape: (None, MAX_SENTS, nb_filter)\n",
    "#reviewsenti_encoder = TimeDistributed(sentiwordEncoder)(review_input)\n",
    "\n",
    "# mask out padding sentences\n",
    "review_encoder = Masking(mask_value=0., input_shape=(MAX_SENTS, gru_dim*2))(review_encoder)\n",
    "\n",
    "rnn_out1 = rnn_layer3(review_encoder) # (batch_size, timesteps, gru_dimx2)\n",
    "#rnn_out2 = rnn_layer4(reviewsenti_encoder)\n",
    "\n",
    "att_out = AttLayer(atten_dim)(rnn_out1)\n",
    "#att_s_out= AttLayer(atten_dim)(rnn_out2)\n",
    "# att_out = Dropout(dropout_rate)(att_out)\n",
    "\n",
    "#main_out= keras.layers.concatenate([att_out,att_s_out])\n",
    "\n",
    "dense = Dense(dense_dim, activation='relu')(att_out)\n",
    "dense = Dropout(dropout_rate)(dense)\n",
    "\n",
    "if categorical_label:\n",
    "    preds = Dense(2, activation='softmax')(dense) # categorical output\n",
    "    model = Model(review_input, preds)\n",
    "    print(model.summary())\n",
    "    # Replicates `model` on multiple GPUs.\n",
    "    # This assumes that your machine has 'gpus' available GPUs.\n",
    "    if gpu_num>1:\n",
    "        model = multi_gpu_model(model, gpus=gpu_num)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['acc'])\n",
    "else:\n",
    "    preds = Dense(1, activation='sigmoid')(dense)\n",
    "    model = Model(review_input, preds)\n",
    "    print(model.summary())\n",
    "    # Replicates `model` on multiple GPUs.\n",
    "    # This assumes that your machine has 'gpus' available GPUs.\n",
    "    if gpu_num>1:\n",
    "        model = multi_gpu_model(model, gpus=gpu_num)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training for epoch 1/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 329s 13ms/step - loss: 0.4202 - acc: 0.7966\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 115s 5ms/step\n",
      "Accuracy: 0.8564\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.80719   0.93640   0.86700     12500\n",
      "          1    0.92428   0.77632   0.84386     12500\n",
      "\n",
      "avg / total    0.86573   0.85636   0.85543     25000\n",
      "\n",
      "Training for epoch 2/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 316s 13ms/step - loss: 0.3072 - acc: 0.8734\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 113s 5ms/step\n",
      "Accuracy: 0.8932\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.88260   0.90696   0.89461     12500\n",
      "          1    0.90432   0.87936   0.89166     12500\n",
      "\n",
      "avg / total    0.89346   0.89316   0.89314     25000\n",
      "\n",
      "Training for epoch 3/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 314s 13ms/step - loss: 0.2782 - acc: 0.8867\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9019\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.91377   0.88760   0.90050     12500\n",
      "          1    0.89073   0.91624   0.90330     12500\n",
      "\n",
      "avg / total    0.90225   0.90192   0.90190     25000\n",
      "\n",
      "Training for epoch 4/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 315s 13ms/step - loss: 0.2550 - acc: 0.8970\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9038\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.89052   0.92080   0.90541     12500\n",
      "          1    0.91801   0.88680   0.90214     12500\n",
      "\n",
      "avg / total    0.90427   0.90380   0.90377     25000\n",
      "\n",
      "Training for epoch 5/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 310s 12ms/step - loss: 0.2436 - acc: 0.9019\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9084\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.92212   0.89224   0.90693     12500\n",
      "          1    0.89562   0.92464   0.90990     12500\n",
      "\n",
      "avg / total    0.90887   0.90844   0.90842     25000\n",
      "\n",
      "Training for epoch 6/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 310s 12ms/step - loss: 0.2351 - acc: 0.9074\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9040\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.94422   0.85864   0.89940     12500\n",
      "          1    0.87039   0.94928   0.90812     12500\n",
      "\n",
      "avg / total    0.90731   0.90396   0.90376     25000\n",
      "\n",
      "Training for epoch 7/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 311s 12ms/step - loss: 0.2253 - acc: 0.9114\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.90638   0.92248   0.91436     12500\n",
      "          1    0.92108   0.90472   0.91283     12500\n",
      "\n",
      "avg / total    0.91373   0.91360   0.91359     25000\n",
      "\n",
      "Training for epoch 8/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 311s 12ms/step - loss: 0.2140 - acc: 0.9173\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 111s 4ms/step\n",
      "Accuracy: 0.9114\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.89294   0.93480   0.91339     12500\n",
      "          1    0.93159   0.88792   0.90923     12500\n",
      "\n",
      "avg / total    0.91227   0.91136   0.91131     25000\n",
      "\n",
      "Training for epoch 9/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 311s 12ms/step - loss: 0.2050 - acc: 0.9199\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9147\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93366   0.89288   0.91282     12500\n",
      "          1    0.89736   0.93656   0.91654     12500\n",
      "\n",
      "avg / total    0.91551   0.91472   0.91468     25000\n",
      "\n",
      "Training for epoch 10/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 311s 12ms/step - loss: 0.1975 - acc: 0.9234\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.91486   0.92064   0.91774     12500\n",
      "          1    0.92014   0.91432   0.91722     12500\n",
      "\n",
      "avg / total    0.91750   0.91748   0.91748     25000\n",
      "\n",
      "Training for epoch 11/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 310s 12ms/step - loss: 0.1864 - acc: 0.9267\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9167\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.92116   0.91136   0.91623     12500\n",
      "          1    0.91229   0.92200   0.91712     12500\n",
      "\n",
      "avg / total    0.91673   0.91668   0.91668     25000\n",
      "\n",
      "Training for epoch 12/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 311s 12ms/step - loss: 0.1836 - acc: 0.9297\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9179\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.92101   0.91416   0.91757     12500\n",
      "          1    0.91479   0.92160   0.91818     12500\n",
      "\n",
      "avg / total    0.91790   0.91788   0.91788     25000\n",
      "\n",
      "Training for epoch 13/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 311s 12ms/step - loss: 0.1757 - acc: 0.9325\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 112s 4ms/step\n",
      "Accuracy: 0.9174\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.92209   0.91184   0.91694     12500\n",
      "          1    0.91281   0.92296   0.91786     12500\n",
      "\n",
      "avg / total    0.91745   0.91740   0.91740     25000\n",
      "\n",
      "Training for epoch 14/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 325s 13ms/step - loss: 0.1696 - acc: 0.9352\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 115s 5ms/step\n",
      "Accuracy: 0.9197\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.91762   0.92224   0.91992     12500\n",
      "          1    0.92185   0.91720   0.91952     12500\n",
      "\n",
      "avg / total    0.91973   0.91972   0.91972     25000\n",
      "\n",
      "Training for epoch 15/15\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 321s 13ms/step - loss: 0.1608 - acc: 0.9389\n",
      "Evaluating...\n",
      "25000/25000 [==============================] - 114s 5ms/step\n",
      "Accuracy: 0.9160\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0    0.93734   0.89152   0.91385     12500\n",
      "          1    0.89658   0.94040   0.91796     12500\n",
      "\n",
      "avg / total    0.91696   0.91596   0.91591     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "for i in range(epoch_num):\n",
    "    print('Training for epoch {}/{}'.format(i+1,epoch_num))\n",
    "    if categorical_label:\n",
    "        model.fit(train_copus_padded, train_label_cat, batch_size=batch_size,epochs=1)\n",
    "    else:\n",
    "        model.fit(train_copus_padded, train_label, batch_size=batch_size,epochs=1)\n",
    "        \n",
    "    print('Evaluating...')\n",
    "    pred_test_prob = model.predict(test_copus_padded, batch_size=batch_size, verbose=True)\n",
    "    # predict the class label\n",
    "    if pred_test_prob.shape[-1]>1:\n",
    "        pred_test = pred_test_prob.argmax(axis=-1)\n",
    "    else:\n",
    "        pred_test = (pred_test_prob>0.5).astype('int32')\n",
    "        pred_test = pred_test.reshape(pred_test.shape[0])\n",
    "\n",
    "    acc = np.sum(pred_test == test_label) / float(len(test_label))\n",
    "\n",
    "    print(\"Accuracy: %.4f\" % (acc))   \n",
    "    print(classification_report(test_label, pred_test, digits=5, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
